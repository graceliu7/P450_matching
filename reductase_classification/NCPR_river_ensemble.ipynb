{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4dffced3618d713eb35573249f37da055ccb4ce8327966404b9b643de5d1677c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skmultiflow.data.data_stream import DataStream\n",
    "from NCPR_functions import load_NCPR, train_test_split\n",
    "\n",
    "from adaptive_xgboost import AdaptiveXGBoostClassifier\n",
    "from river import metrics, preprocessing, stream, linear_model, tree, ensemble, compat\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import sklearn\n",
    "import model_to_river\n",
    "import my_pipeline\n",
    "from ensemble_class import EnsembleModel\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed, parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(stream, model):\n",
    "    for data, target in stream:\n",
    "        x = model.transform_one(data)\n",
    "        model = model.learn_one(x, target)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(stream, model):\n",
    "    for data, target in stream:\n",
    "        y_pred = model.predict_one(data)\n",
    "        metric = metric.update(target, y_pred)\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def river_pipeline(X, y, classifier):  \n",
    "    model = my_pipeline.Pipeline(\n",
    "        classifier\n",
    "    )\n",
    "    metric = metrics.Accuracy()\n",
    "\n",
    "\n",
    "    for i in range(len(X)-1):\n",
    "        train_stream = stream.iter_array(\n",
    "            X[i], y[i],\n",
    "            feature_names = ['x{}'.format(j) for j in range(len(X[i]))] \n",
    "        )\n",
    "        \n",
    "        model = train_model(train_stream, model)\n",
    "\n",
    "    test_stream = stream.iter_array(\n",
    "        X[-1], y[-1],\n",
    "        feature_names = ['x{}'.format(j) for j in range(len(X[-1]))] \n",
    "    )\n",
    "    for data, target in test_stream:\n",
    "        y_pred = model.predict_one(data)      # make a prediction\n",
    "        metric = metric.update(target, y_pred)\n",
    "    return test_model(test_stream, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_params(params, model_name, data, labels):\n",
    "    xtrain, ytrain, xtest, ytest = train_test_split(data, labels)\n",
    "    classes = np.unique(ytrain)\n",
    "\n",
    "    if model_name = \"SGD\":\n",
    "        model = compat.convert_sklearn_to_river(sklearn.linear_model.SGDClassifier(**params), classes=classes)\n",
    "    elif model_name = \"Decision Tree\":\n",
    "        model = tree.ExtremelyFastDecisionTreeClassifier(**params)\n",
    "    elif model_name = \"Random Forest\":\n",
    "        model = ensemble.AdaptiveRandomForestClassifier(**params)\n",
    "    elif model_name = \"Hoeffding Tree\":\n",
    "        model = tree.HoeffdingAdaptiveTreeClassifier(**params)\n",
    "\n",
    "    X = [xtrain, xtest]\n",
    "    y = [ytrain, ytest]\n",
    "    return river_pipeline(X,y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams(param_grid, model_name, data, labels, csv_fname, n_jobs, return_best_param=False):\n",
    "    param_grid = ParameterGrid(param_grid)\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(try_params)(params, model_name, data, labels) for params in tqdm(param_grid))\n",
    "\n",
    "    column_names = list(results[0][0].keys())\n",
    "    column_names.append('Score')\n",
    "    rows = []\n",
    "    scores = []\n",
    "    for i in range(len(results)):\n",
    "        row = list(results[i][0].values())\n",
    "        row.append(results[i][1])\n",
    "        rows.append(row)\n",
    "        scores.append(results[i][1])\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "    df.to_csv(csv_fname, header=True)\n",
    "\n",
    "    if return_best_param:\n",
    "        best_index = scores.index(max(scores))\n",
    "        best_params = results[best_index][0]\n",
    "        return best_params\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data, NCPR_df = load_NCPR('data/NCPR_bert.npz', 'data/uniprot-NCPR.tab', 'data/uniprot-NCPR.fasta')\n",
    "xtrain, ytrain, xtest, ytest = train_test_split(dict_data, NCPR_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(np.unique(ytrain))\n",
    "\n",
    "sgd_model = compat.convert_sklearn_to_river(sklearn.linear_model.SGDClassifier(loss='log', eta0= 0.1,learning_rate = 'constant'), classes=classes)\n",
    "tree_model = tree.ExtremelyFastDecisionTreeClassifier(\n",
    "    grace_period=100,\n",
    "    split_confidence=1e-5,\n",
    "    min_samples_reevaluate=100)\n",
    "forest_model = ensemble.AdaptiveRandomForestClassifier(n_models=10)\n",
    "hoeffding_model = tree.HoeffdingAdaptiveTreeClassifier(\n",
    "    grace_period=100,\n",
    "    split_confidence=1e-5,\n",
    "    leaf_prediction='nb',\n",
    "    nb_threshold=10,\n",
    "    seed=0\n",
    "    )\n",
    "#xgb_model = model_to_river.Multiflow2RiverClassifier(AdaptiveXGBoostClassifier(update_strategy='push'), classes=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [xtrain, xtest]\n",
    "y = [ytrain, ytest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_results = Parallel(n_jobs=5)(delayed(river_pipeline)(X,y,sgd_model) for i in tqdm(50))\n",
    "sgd_score = np.nanmean(sgd_results)\n",
    "with open('sgd_results.txt', 'w') as f:\n",
    "    f.write('average score: ' + str(sgd_score) + '\\n')\n",
    "    for i in sgd_results:\n",
    "        f.write(str(i) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_results = Parallel(n_jobs=5)(delayed(river_pipeline)(X,y,tree_model) for i in tqdm(50))\n",
    "tree_score = np.nanmean(tree_results)\n",
    "with open('tree_results.txt', 'w') as f:\n",
    "    f.write('average score: ' + str(tree_score) + '\\n')\n",
    "    for i in tree_results:\n",
    "        f.write(str(i) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_results = Parallel(n_jobs=5)(delayed(river_pipeline)(X,y,forest_model) for i in tqdm(50))\n",
    "forest_score = np.nanmean(forest_results)\n",
    "with open('forest_results.txt', 'w') as f:\n",
    "    f.write('average score: ' + str(forest_score) + '\\n')\n",
    "    for i in forest_results:\n",
    "        f.write(str(i) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoeffding_results = Parallel(n_jobs=5)(delayed(river_pipeline)(X,y,forest_model) for i in tqdm(50))\n",
    "hoeffding_score = np.nanmean(hoeffding_results)\n",
    "with open('hoeffding_results.txt', 'w') as f:\n",
    "    f.write('average score: ' + str(hoeffding_score) + '\\n')\n",
    "    for i in hoeffding_results:\n",
    "        f.write(str(i) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = EnsembleModel(models=[sgd_model,tree_model,forest_model,hoeffding_model], classes=classes, weights = [sgd_score, tree_score, forest_score, hoeffding_Score])\n",
    "ensemble_results = Parallel(n_jobs=5)(delayed(river_pipeline)(X,y,ensemble_model) for i in tqdm(50))\n",
    "ensemble_score = np.nanmean(hoeffding_results)\n",
    "with open('ensemble_results.txt', 'w') as f:\n",
    "    f.write('average score: ' + str(ensemble_score) + '\\n')\n",
    "    for i in ensemble_results:\n",
    "        f.write(str(i) + '\\n')"
   ]
  }
 ]
}